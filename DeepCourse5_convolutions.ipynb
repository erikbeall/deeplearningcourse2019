{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import signal\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "# define Activation layers and derivatives\n",
    "Sigmoid = lambda x: 1.0/(1.0000000000001 + np.exp(-x))\n",
    "Sigmoid_delta = lambda x, Sigmoid: Sigmoid(x)*(1-Sigmoid(x))\n",
    "Relu = lambda x: np.maximum(x, 0.0)\n",
    "Relu_delta = lambda x: np.maximum(x+0.0001, 0.0)/np.maximum(x, 0.0001)-0.0001\n",
    "# define loss layers\n",
    "Softmax = lambda x: np.exp(x)/np.nansum(np.exp(x), axis=0)\n",
    "one_hot = lambda labels, n_classes: np.eye(n_classes)[np.array(labels).reshape(-1)].transpose()\n",
    "ce_loss = lambda labels,output: -np.nansum(np.log(Softmax(output))* one_hot(labels, output.shape[0]), axis=0)\n",
    "ce_softmax_delta = lambda labels,output: output - one_hot(labels, output.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a Max Pooling layer with downsampling integer size. Reshapes and takes the maximum across the downsampled reshape dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "MaxPool = lambda data, ds=2: data[:, :(data.shape[1] // ds)*ds, :(data.shape[2] // ds)*ds].reshape(data.shape[0], data.shape[1] // ds, ds, data.shape[2] // ds, ds).max(axis=(2, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional neural networks\n",
    "\n",
    "Open a single example image dataset: the number 5 from the MNIST data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgfile='data/number5.jpg'\n",
    "from PIL import Image\n",
    "img_pil = Image.open(imgfile)\n",
    "img_pil_32x32= img_pil.resize((32,32), Image.LINEAR)\n",
    "# reshape as having a single input channel\n",
    "# we're going to be working with input and output channels as we go thru the network\n",
    "data = np.asarray(img_pil_32x32).astype(np.float32).reshape((32,32,1))\n",
    "labels=np.asarray([[5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conv weights are in form channels_in (I), channels_out (J), kernel_width, kernel_height and convolution will proceed with one kernel (e.g. $weight[i,j,:,:]$) over each channel i of the I channels of data/activation flowing into this layer and these will be summed over all i to generate the jth output feature map/image, resulting in J output channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels=1\n",
    "out_channels=8\n",
    "# typically (but not necessarily) the filter is symmetric\n",
    "filter_size=5\n",
    "weights = np.random.randn(in_channels, out_channels, filter_size, filter_size)\n",
    "# Bias on the other hand is just like the fully-connecteds, there will be one bias per output channel\n",
    "biases = np.random.randn(out_channels, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 1)\n",
      "(8, 36, 36)\n"
     ]
    }
   ],
   "source": [
    "# so we will be doing something like this:\n",
    "output=[]\n",
    "for j in range(out_channels):\n",
    "    temp=None\n",
    "    for i in range(in_channels):\n",
    "        if temp is None:\n",
    "            temp = signal.convolve2d(weights[i,j,:,:],data[:,:,i])\n",
    "        else:\n",
    "            temp += signal.convolve2d(weights[i,j,:,:],data[:,:,i])\n",
    "    output.append(temp/in_channels + biases[j])\n",
    "output = np.asarray(output)\n",
    "print(data.shape)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the channels dimension naturally is easier to work with if it comes first. Remember we'll be dealing with larger networks and each feature map, activation map should have the same structure. So at this point, we should permute the data so channels is the first dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "data = data.transpose((2, 0, 1))\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional layer and its variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-liner with list comprehension\n",
    "Conv2D = lambda data, weights, biases: \\\n",
    "    np.asarray([sum( \\\n",
    "        [signal.convolve2d(data[i,:,:], weights[i,j,:,:].squeeze(), mode='same') \\\n",
    "         for i in range(weights.shape[0])]) \\\n",
    "        + biases[j] for j in range(weights.shape[1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding\n",
    "signal.convolve2d has three modes, corresponding to common practices when using convolutions. Strictly, the traditional convolution is 'full' convolution, but we usually use 'same' or 'valid' modes.\n",
    "\n",
    "'same' mode means a constant padding (zeros, but can be adjusted) is applied to expand the image so the output will end up the same size as the input. This creates a padding = (filter_size//2)\n",
    "\n",
    "'valid' mode means the filter is only applied in regions of the image where the kernel can be contained, meaning the edges will get cut off\n",
    "         size_output = size_input - 2*(filter_size//2)\n",
    "\n",
    "'full' is the default, meaning the mathematical convolution will be applied, which will expand the image to\n",
    "         size_output = size_input + 2*(filter_size//2)\n",
    "\n",
    "\n",
    "Note its not uncommon to skip biases for convolutional layers (usually with something like use_bias=False in one of the platforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filter-matched padding, input data shape (1, 32, 32), output data shape: (8, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "# pass data thru conv layer defined by the weights and biases\n",
    "output = Conv2D(data, weights, biases)\n",
    "print('Filter-matched padding, input data shape '+str(data.shape)+', output data shape: '+str(output.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variation: padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No padding, output data shape: (8, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "Conv2DNoPad = lambda data, weights, biases, pad=0: np.asarray([sum( [signal.convolve2d(data[i,:,:], weights[i,j,:,:].squeeze(), mode='valid') for i in range(weights.shape[0])] )+biases[j] for j in range(weights.shape[1])])\n",
    "print('No padding, output data shape: '+str(Conv2DNoPad(data, weights, biases).shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variation: stride\n",
    "Please note, this is not a robust implementation, ideally we'd want to define starts/stops of strides, and limit needless computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padding and stride==2, output data shape: (8, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "Conv2DStride = lambda data, weights, biases, stride=2: np.asarray([sum( [signal.convolve2d(data[i,:,:], weights[i,j,:,:].squeeze(), mode='same') for i in range(weights.shape[0])] )+biases[j] for j in range(weights.shape[1])])[:,::stride,::stride]\n",
    "print('Padding and stride==2, output data shape: '+str(Conv2DNoPad(data, weights, biases).shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variation: group\n",
    "group convolution (with groups=channels) or depthwise convolution (with groups<channels), the number of filters must match the number of input channels and the output is same size (and channels) as input. Each filter is applied to ONLY one channel, meaning convolution operations are done separately per channel in this layer note, there are only C-channels, no input/output channels in the weights. ALSO note, from here on, we've redefined data to start with the channel dimension first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input to depthwise: (8, 32, 32), output: (8, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "depthwise_weights = np.random.randn(out_channels, filter_size, filter_size)\n",
    "Conv2DDepthwise = lambda data, weights, biases: np.asarray([signal.convolve2d(data[i,:,:], depthwise_weights[i,:,:].squeeze(), mode='same')+biases[i] for i in range(weights.shape[0])] )\n",
    "print('Input to depthwise: '+str(output.shape)+', output: '+str(Conv2DDepthwise(output, depthwise_weights, biases).shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variation: depth-separable convolution\n",
    "Here, we do a MxN with C-groupwise (depthwise) convolution followed by a 1x1 regular convolution with as many channels as makes sense, here lets double the number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nope, scipy convolve2d only supports actual 2D convolution\n",
      "input to depth-separable pair of convolutions: (8, 32, 32), output: (16, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "weights_1x1 = np.random.randn(out_channels, 2*out_channels, 1, 1)\n",
    "biases_1x1 = np.random.randn(2*out_channels, 1)\n",
    "# however, scipy's convolve2d doesn't really support 1x1 (non-2D) convolutions, so we have to implement it differently\n",
    "output_depthwise = Conv2DDepthwise(output, depthwise_weights, biases)\n",
    "try:\n",
    "    output_depth_sep = Conv2D(output_depthwise, weights_1x1, biases_1x1)\n",
    "except:\n",
    "    print('Nope, scipy convolve2d only supports actual 2D convolution')\n",
    "\n",
    "Conv2D_1x1 = lambda data, weights, biases: np.asarray([sum([data[i,:,:]*weights[i, c, 0, 0] for i in range(weights.shape[0])]) for c in range(weights.shape[1])])\n",
    "output_depth_sep = Conv2D_1x1(output_depthwise, weights_1x1, biases_1x1)\n",
    "print('input to depth-separable pair of convolutions: '+str(output.shape)+', output: '+str(output_depth_sep.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variation:dilated/atrous convolution\n",
    "For this, we insert \"holes\" in the filter before applying, equivalent to expanding the filter and filling with zeros so a 3x3 filter with dilation=2 becomes a 5x5 without any added computation (assuming its implemented well, we're going to be lazy and keep using scipy's convolve2d), and a 3x3 with dilation=3 becomes a 7x7 filter. You could say it expands the \"receptive area\" of a filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dilation=2\n",
    "dilated_filter_size = dilation*(filter_size-1)+1\n",
    "dilated_weights = np.zeros( (weights.shape[0], weights.shape[1], (weights.shape[2]-1)*dilation + 1, (weights.shape[3]-1)*dilation + 1) )\n",
    "dilated_weights[:, :, ::dilation, ::dilation]=weights\n",
    "output_atrous = Conv2D(data, dilated_weights, biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variation: up-volution (fractional-strided convolution)\n",
    "Apply the filter to the input data but here the input data is dilated (atrous) like above it is also called transposed convolution, and also sometimes called deconvolution, which it isn't, but this is what they're referring to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmap = output\n",
    "dilated_fmap = np.zeros( (fmap.shape[0], fmap.shape[1]*dilation, fmap.shape[2]*dilation) )\n",
    "dilated_fmap[:, ::dilation, ::dilation]=fmap\n",
    "# note, like some of these layers, this implementation involves a choice of where to index from, so\n",
    "# platforms can differ in the fine details without you knowing anything about it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional network builder\n",
    "For this network, we will combine convolutions and fully connected layers. We will need a \"flatten\" layer so the fully connected layers can accept the last convolutional layer, and we'll use maxpooling layers as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "def get_CNN_params(w_scale=0.01, b_scale=0.0, activations=[], conv_sizes=[], maxpool_sizes=[], fc_sizes=[]):\n",
    "    # default is lenet-5\n",
    "    if len(conv_sizes)==0:\n",
    "        conv_sizes=[(1,6,5,5), 0, (6,16,5,5), 0, 0, 0, 0]\n",
    "        maxpool_sizes=[1, 2, 1, 2, 1, 1, 1]\n",
    "        fc_sizes=[0, 0, 0, 0, 400, 120, 84, 10]\n",
    "    if len(activations)==0:\n",
    "        activations=[Sigmoid, None, Sigmoid, None, Sigmoid, Sigmoid, None]\n",
    "    params=[]\n",
    "    first_fc=True\n",
    "    for i in range(len(fc_sizes)-1):\n",
    "        layer=collections.namedtuple('layer',['type', 'pool','weight','bias','activation'])\n",
    "        if fc_sizes[i]>0:\n",
    "            if first_fc:\n",
    "                first_fc=False\n",
    "                layer=collections.namedtuple('layer',['type', 'pool','weight','bias','activation'])\n",
    "                layer.type='Flatten'\n",
    "                layer.activation = None\n",
    "                params.append(layer)\n",
    "                layer=collections.namedtuple('layer',['type', 'pool','weight','bias','activation'])\n",
    "            layer.type='FullyConnected'\n",
    "            layer.weights = w_scale * np.random.randn(fc_sizes[i+1], fc_sizes[i])\n",
    "            print('layer weights ',layer.weights.shape)\n",
    "            layer.bias  = b_scale * np.random.randn(fc_sizes[i+1], 1)\n",
    "            print('layer bias ',layer.bias.shape)\n",
    "        elif maxpool_sizes[i]>1:\n",
    "            layer.type='MaxPool'\n",
    "            layer.weight = None\n",
    "            layer.bias  = None\n",
    "        else:\n",
    "            layer.type='Conv2D'\n",
    "            layer.weights = w_scale * np.random.random(conv_sizes[i])\n",
    "            layer.bias  = b_scale * np.random.randn(conv_sizes[i][1], 1)\n",
    "        layer.activation = activations[i]\n",
    "        params.append(layer)\n",
    "    if params[-1].type=='Conv2D':\n",
    "        # if last layer was Conv, append a flatten layer\n",
    "        layer=collections.namedtuple('layer',['type', 'pool','weight','bias','activation'])\n",
    "        layer.type='Flatten'\n",
    "        layer.activation = None\n",
    "        params.append(layer)\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup network config, use valid pooling from here on in forward passes\n",
    "Conv2D = lambda data, weights, biases: np.asarray([sum( [signal.convolve2d(data[i,:,:], weights[i,j,:,:].squeeze(), mode='valid') for i in range(weights.shape[0])] )+biases[j] for j in range(weights.shape[1])])\n",
    "Conv2D_1x1 = lambda data, weights, biases: np.asarray([sum([data[i,:,:]*weights[i, c, 0, 0] for i in range(weights.shape[0])]) for c in range(weights.shape[1])])\n",
    "activation_fn=Sigmoid\n",
    "delta_activation_fn=Sigmoid_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: fully convolutional (i.e., no fc layers)\n",
    "# 32x32x1 -> 8x28x28 (ds to 14x14) -> 32x10x10 (ds to 5x5) -> 64x1x1 -> 10x1x1 -> flatten\n",
    "params_fcn = get_CNN_params(activations=[activation_fn, None, activation_fn, \\\n",
    "                                         None, activation_fn, None], \\\n",
    "                            conv_sizes=[(1,8,5,5),0,(8,32,5,5),0,(32,64,5,5),(64,10,1,1)], \\\n",
    "                            maxpool_sizes=[1,2,1,2,1,1,1], fc_sizes=[0,0,0,0,0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer weights  (120, 400)\n",
      "layer bias  (120, 1)\n",
      "layer weights  (84, 120)\n",
      "layer bias  (84, 1)\n",
      "layer weights  (10, 84)\n",
      "layer bias  (10, 1)\n"
     ]
    }
   ],
   "source": [
    "# Example 2: get the LeNet-5 network arch\n",
    "params_lenet5 = get_CNN_params(activations=[activation_fn, None, activation_fn, None, activation_fn, activation_fn, None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create forward pass function capable of handling this layer-based param structure\n",
    "def forward(data, params, forward_only=True):\n",
    "    activations=[data]\n",
    "    features=[]\n",
    "    for layer in params:\n",
    "        print(layer.type)\n",
    "        print('activations flowing into this layer: ', activations[-1].shape)\n",
    "        if layer.type == 'Flatten':\n",
    "            features.append(activations[-1].reshape((-1, 1)))\n",
    "            # next layer for dot product MUST have shape (N,1) not (N,)\n",
    "            activations.append(features[-1])\n",
    "            continue\n",
    "        elif layer.type == 'Conv2D':\n",
    "            if layer.weights.shape[-1]>1:\n",
    "                features.append(Conv2D(activations[-1], layer.weights, layer.bias))\n",
    "            else:\n",
    "                features.append(Conv2D_1x1(activations[-1], layer.weights, layer.bias))\n",
    "        elif layer.type == 'FullyConnected':\n",
    "            features.append(np.dot(layer.weights, activations[-1]) + layer.bias)\n",
    "        elif layer.type == 'MaxPool':\n",
    "            features.append(MaxPool(activations[-1]))\n",
    "        activations.append(layer.activation(features[-1]) if layer.activation is not None else features[-1])\n",
    "    if forward_only:\n",
    "        return activations[-1]\n",
    "    else:\n",
    "        return activations,features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backpropagation for convolutional network\n",
    "Remembering that convolution is defined as a backwards operator of the filter over the local pixels. This means the 2D convolution is like flipping the weights in both axes and applying directly. Backpropagation for convolution is like with fully connected except the weights multiplication to get the current layer's gradient must be done with similarly flipped weights from the subsequent layer, and with flipped activation flowing from the current layer:\n",
    "\n",
    "dL/dW = layer_gradient * activation(flipped activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2D\n",
      "activations flowing into this layer:  (1, 32, 32)\n",
      "MaxPool\n",
      "activations flowing into this layer:  (8, 28, 28)\n",
      "Conv2D\n",
      "activations flowing into this layer:  (8, 14, 14)\n",
      "MaxPool\n",
      "activations flowing into this layer:  (32, 10, 10)\n",
      "Conv2D\n",
      "activations flowing into this layer:  (32, 5, 5)\n",
      "Conv2D\n",
      "activations flowing into this layer:  (64, 1, 1)\n",
      "Flatten\n",
      "activations flowing into this layer:  (10, 1, 1)\n",
      "Single forward pass loss on initialized network:  [2.301]\n"
     ]
    }
   ],
   "source": [
    "# run on fully-convolutional network\n",
    "activations,features = forward(data, params_fcn, forward_only=False)\n",
    "\n",
    "softmax_outputs = Softmax(activations[-1])\n",
    "loss = ce_loss(labels, activations[-1])\n",
    "print('Single forward pass loss on initialized network: ',loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting complex enough that we need to track the layers, weights and biases better\n",
    "gradients={'layers': [], 'weights': [], 'biases': []}\n",
    "# append the final layer gradient from what we know to be the log-likelihood+softmax gradient\n",
    "gradients['layers'].append(softmax_outputs - one_hot(labels, softmax_outputs.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
